<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 3 Write-Up</h1>
		<div style="text-align: center;">Names: </div>

		<br>

		Link to webpage: <a href="https://andywa-ng.github.io/hw-webpages-andy/">https://andywa-ng.github.io/hw-webpages-andy/</a>
		<br>
		Link to GitHub repository: <a href="https://github.com/cal-cs184-student/sp25-hw3-gower-power-2">https://github.com/cal-cs184-student/sp25-hw3-gower-power-2</a>
		
		<!--
		We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		Give a high-level overview of what you implemented in this homework. Think about what you've built as a whole. Share your thoughts on what interesting things you've learned from completing the homework.

		<h2>Part 1: Ray Generation and Scene Intersection</h2>
		
		<h3>Ray Generation</h3>
        <p>
            The first step in the rendering pipeline is ray generation. Rays are created from the camera and pass through each pixel of the image to determine what the camera "sees" in the scene.
        </p>
        <p>
            For each pixel, multiple rays are generated for anti-aliasing. Pixel coordinates are mapped to normalized image coordinates (<code>[0, 1]</code> in both x and y), which are then transformed into camera space. The camera is at the origin <code>(0, 0, 0)</code> and looks along the <code>-Z</code> axis.
        </p>
        <p>
            The ray's origin is the camera's position, and its direction is determined by the corresponding point on the virtual sensor plane (at <code>Z = -1</code>). The ray is then transformed into world space using the camera-to-world transformation matrix.
        </p>

        <h3>Ray Intersection</h3>
        <p>
            After ray generation, the next step is to determine if rays intersect with objects in the scene. This involves intersection tests for triangles and spheres.
        </p>

        <h4>Triangle Intersection</h4>
        <p>
            The triangle intersection algorithm uses ray-plane intersection and barycentric coordinates:
        </p>
        <ol>
            <li>
                Ray-Plane Intersection:
                <ul>
                    <li>Compute the plane equation using the triangle's vertices.</li>
                    <li>Solve for the ray parameter <code>t</code> where the ray intersects the plane.</li>
                    <li>Check if <code>t</code> lies within the valid range <code>[min_t, max_t]</code>.</li>
                </ul>
            </li>
            <li>
                Barycentric Coordinates:
                <ul>
                    <li>Compute barycentric coordinates <code>(u, v)</code> of the intersection point relative to the triangle.</li>
                    <li>Check if the point lies inside the triangle by verifying <code>u >= 0</code>, <code>v >= 0</code>, and <code>u + v <= 1</code>.</li>
                </ul>
            </li>
            <li>
            Interpolate Normals:
                <ul>
                    <li>If the intersection is valid, interpolate the vertex normals using barycentric coordinates to compute the surface normal.</li>
                </ul>
            </li>
        </ol>

        <h4>Sphere Intersection</h4>

        <ol>
            <li>
                Quadratic Equation:
                <ul>
                    <li>Compute coefficients <code>a</code>, <code>b</code>, and <code>c</code> based on the ray's origin, direction, and sphere's center and radius.</li>
                    <li>Solve for roots <code>t1</code> and <code>t2</code> using the quadratic formula.</li>
                </ul>
            </li>
            <li>
                Root Validity Check:
                <ul>
                    <li>Check if the roots are within the valid range <code>[min_t, max_t]</code>.</li>
                    <li>Select the smallest valid <code>t</code> value as the closest intersection.</li>
                </ul>
            </li>
            <li>
                Compute Normal:
                <ul>
                    <li>Compute the surface normal at the intersection point as the vector from the sphere's center to the intersection point, normalized.</li>
                </ul>
            </li>
        </ol>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="images/CBspheres.png" width="400px"/>
				  <figcaption>Spheres</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="images/teapot.png" width="400px"/>
				  <figcaption>Teapot</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		
		<h2>Part 2: Bounding Volume Hierarchy</h2>
		
		<h3>BVH Construction Algorithm</h3>
        <p>
            The BVH construction algorithm recursively partitions the scene primitives into a binary tree. Each node in the tree contains a bounding box that encloses all primitives in its subtree.
        </p>
        <ol>
            <li>
                Compute Bounding Box:
                <ul>
                    <li>For the current set of primitives, compute the bounding box that encloses all of them.</li>
                </ul>
            </li>
            <li>
                Check Leaf Nodes:
                <ul>
                    <li>If the number of primitives is less than or equal to the maximum leaf size, create a leaf node with the computed bounding box and store the primitives.</li>
                </ul>
            </li>
            <li>
                Split Primitives:
                <ul>
                    <li>Choose the axis with the largest extent of the bounding box for splitting.</li>
                    <li>Compute the split point as the average centroid of the primitives along the chosen axis.</li>
                    <li>Partition the primitives into left and right groups based on the split point.</li>
                </ul>
            </li>
            <li>
                Recursively construct the left and right child nodes using the partitioned primitives.</li>
            </li>
			
		<br>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
				<tr>
				<td style="text-align: center;">
					<img src="images/cow.png" width="400px"/>
					<figcaption>Cow</figcaption>
				</td>
				<td style="text-align: center;">
					<img src="images/maxplank.png" width="400px"/>
					<figcaption>Maxplank</figcaption>
				</td>
				</tr>
				<td style="text-align: center;">
					<img src="images/lucy.png" width="400px"/>
					<figcaption>Lucy</figcaption>
				</td>
				</tr>
			</table>
		</div>
        </ol>

		BVH acceleration significantly reduces rendering times for scenes with moderately complex geometries. Without BVH, rendering times are very long due to the high number of ray-primitive intersection tests. With BVH, the rendering times are reduced by an order of magnitude, as the BVH allows for efficient removal of large groups of primitives that a ray is guaranteed not to intersect.
		
		For example, when rendering dae/sky/CBlucy.dae, my computer only took 0.89s with BVH, compared to slightly under 34s without.

		<h2>Part 3: Direct Illumination</h2>

		<h3>Uniform Hemisphere Sampling</h4>
		<ol>
			<li>Creates local coordinate system with normal as Z-axis
			</li>
			<li>Uses uniform hemisphere sampler to get random directions
			</li>
			<li>Creates ray with epsilon offset to prevent self-intersection
			</li>
			<li>Checks if ray hits an emissive object (light source)
			</li>
			<li>Compute BSDF, cosine term, and light contribution
			</li>
			<li>Normalizes by sample count and hemisphere PDF (1/(2Ï€))
			</li>
		</ol>


            <h3>Light Importance Sampling</h3>
			<ol>
				<li>Process each light source in the scene
				</li>
				<li>Get light direction, distance, PDF and emitted radiance
				</li>
				<li>Create shadow ray with precise distance bounds
				</li>
				<li>Check if path to light is unobstructed
				</li>
				<li>Compute full lighting contribution with proper PDF
				</li>
				<li>Optimize for delta lights that need only one sample
				</li>
			</ol>

	<br>

	<div style="display: flex; flex-direction: column; align-items: center;">
		<table style="width: 100%; text-align: center; border-collapse: collapse;">
			<tr>
			<td style="text-align: center;">
				<img src="images/direct lighting.png" width="400px"/>
				<figcaption>Uniform Hemisphere (64 samples)</figcaption>
			</td>
			<td style="text-align: center;">
				<img src="images/importance sampling.png" width="400px"/>
				<figcaption>Importance Sampling (16 samples)</figcaption>
			</td>
			</tr>
		</table>
	</div>

	<br>
	With hemisphere sampling, soft shadows remain noisy and speckled even with 64 samples.
	With importance sampling, clean soft shadows emerge with just 16 samples.

	<br>

    <div class="analysis">
        <p>
            The uniform hemisphere sampling method produces noisier results because it wastes samples on directions that don't contribute to illumination (like empty space or non-emissive objects), requiring many more samples to converge. Light importance sampling dramatically reduces noise by focusing samples on directions known to contribute light (toward actual light sources), with each sample providing more meaningful information. While hemisphere sampling handles all lighting situations uniformly, importance sampling is particularly effective for small or point light sources where uniform sampling would rarely hit the light. The tradeoff is that importance sampling requires more complex light-specific sampling code and PDF calculations, but the visual quality improvement is substantial, especially for scenes with small or directional light sources.
        </p>
    </div>


		<h2>Part 4: Global Illumination</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		<h2>Part 5: Adaptive Sampling</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		<h2>(Optional) Part 6: Extra Credit Opportunities</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
		
		<figure>
			<img src="images/example_image.png" alt="Cornell Boxes with Bunnies" style="width:70%"/>
			<figcaption>You can add images with captions!</figcaption>
		</figure>

		<h2>Additional Notes (please remove)</h2>
		<ul>
			<li>You can also add code if you'd like as so: <code>code code code</code></li>
			<li>If you'd like to add math equations, 
				<ul>
					<li>You can write inline equations like so: \( a^2 + b^2 = c^2 \)</li>
					<li>You can write display equations like so: \[ a^2 + b^2 = c^2 \]</li>
				</ul>
			</li>
		</ul>
		</div>
	</body>
</html>